\chapter{The Gaussian Radon transform of polynomials}{}

Unlike the Radon transform, the Gaussian Radon transform is well defined on polynomials. In this chapter we investigate the GRT from this perspective, as a linear operator between polynomial spaces. In particular we prove a simple formula for the GRT of multivariate Hermite polynomials. We extend this result to some generalizations of the GRT.

We begin this chapter by proving a formula for the GRT of the multivariate Hermite polynomials defined in the previous section. Recall that for $\alpha \in \NN_0^n$ the polynomials $H_\alpha(x)$ can be defined by the generating function
\[
  e^{\langle x, y\rangle - \frac{\|y\|^2}2} = \sum_{\alpha \in \NN_0^n} \frac{H_\alpha(x)}{\alpha!} y^\alpha
\]
where $\alpha! = \alpha_1! \cdots \alpha_n!$. These are related to the classical Hermite polynomials by
\[
  H_\alpha(x) = \prod_{i=1}^n H_{\alpha_i}(x_i)
\]
where, for $k \in \NN_0^\infty$, the classical polynomials $H_{k}(p)$ can be defined by
\[
  e^{pt - \frac{t^2}2} = \sum_{k = 0}^\infty \frac{H_k(p)}{k!}t^k.
\]

\begin{proposition} \label{prop:GRTHermite}
  Let $\omega \in S^{n-1}$ and $p \in \RR$ be fixed. If $|\alpha| = k$, then the GRT of the multivariate Hermite polynomial $H_\alpha$ is
  \begin{equation}\label{eq:GRH}
    GR_{H_\alpha}(\omega, p) = H_k(p)\omega^\alpha
  \end{equation}
\end{proposition}

\begin{proof}
  Recall that the generating function $\phi(x) = e^{\langle x, y\rangle - \frac{\|y\|^2}2}$ converges absolutely for all $x,y \in \RR^n$. Consider the GRT of $\phi$,
  \begin{align*}
    GR_{\phi}(\omega, p) 
      &= \int\mclimits_{\langle x, \omega \rangle = p} \phi(x) w_{n-1}(x - p\omega)~dx.
    % \\&= \int\mclimits_{\langle x, \omega \rangle = 0} \phi(x + p\omega) w_{n-1}(x)~dx
  \end{align*}
  Immediately we can expand $\phi(x)$, interchanging integral and series, to see
  \begin{equation} \label{eq:GRTPhiExpansion1}
    \begin{split}
      GR_{\phi}(\omega, p)
        &= \sum_{\alpha \in \NN_0^n} \frac1{\alpha!} y^\alpha \int\mclimits_{\langle x, \omega\rangle = p} H_\alpha(x) w_{n-1}(x - p\omega)~dx
      \\&= \sum_{\alpha \in \NN_0^n} \frac{GR_{H_\alpha}(\omega, p)}{\alpha!} y^\alpha.
    \end{split}
  \end{equation}
  On the other hand, we will be able to show that
  \begin{equation} \label{eq:GRTPhiExpansion2}
    GR_{\phi}(\omega, p) 
    = \sum_{k = 0}^\infty \sum_{|\alpha| = k} \frac{H_k(p)\omega^\alpha}{\alpha!} y^\alpha.
  \end{equation}
  Thus, being careful to note that the series (\ref{eq:GRTPhiExpansion1}) and (\ref{eq:GRTPhiExpansion2}) converge absolutely, we can compare coefficients for the desired formula. In order to derive the second expansion we begin by translating our integral onto the linear subspace $\langle x, \omega\rangle = 0$, via the change of variables $x \mapsto x + p\omega$:
  \begin{equation}\label{eq:GRTPhiExpansion21}
    \begin{split}
      GR_{\phi}(\omega, p) 
        &= \int\mclimits_{\langle x, \omega\rangle = 0} \phi(x + p\omega) w_{n-1}(x) ~dx 
      \\&= \int\mclimits_{\langle x, \omega\rangle = 0} e^{\langle x + p\omega, y \rangle - \frac{\|y\|^2}2}(2\pi)^{-\frac{n-1}2}e^{-\frac{\|x\|^2}2} ~dx
      \\&= e^{p \langle \omega, y\rangle - \frac{\|y\|^2}2} \int\mclimits_{\langle x, \omega\rangle = 0}e^{\langle x, y\rangle - \frac{\|x\|^2}2} (2\pi)^{-\frac{n-1}2} ~dx
    \end{split}
  \end{equation}
  Now in order to compute the right side integral we consider the orthogonal decomposition $y = y_\omega + y_{\omega^\perp}$, where
  \[
    y_\omega = \langle y, \omega \rangle \omega \qquad y_{\omega^\perp} = y - y_\omega.
  \]
  We make two observations about this decomposition of $y$: First, 
  \begin{equation}\label{eq:GRTPhiExpansion22}
    \|y\|^2 
      = \|y_\omega\|^2 + \|y_{\omega^\perp}\|^2 
      = \langle y, \omega\rangle^2 + \|y_{\omega^\perp}\|^2
  \end{equation}
  and second, for $x$ in the linear subspace $\langle x, \omega\rangle = 0$ we have
  \[
    \langle x, y \rangle
      = \langle x, \omega \rangle \langle y, \omega \rangle + \langle x, y_{\omega^\perp} \rangle 
      = \langle x, y_{\omega^\perp} \rangle.
  \]
  This second observation allows us to solve the integral at the end of (\ref{eq:GRTPhiExpansion21}). By completing the square $\|x - y_{\omega^\perp}\| = \|y_{\omega^\perp}\|^2 - 2\langle x, y_{\omega^\perp} \rangle + \|x\|^2$, we have
  \begin{align*}
    \int\mclimits_{\langle x, \omega\rangle = 0}e^{\langle x, y\rangle - \frac{\|x\|^2}2} (2\pi)^{-\frac{n-1}2} ~dx
      &= e^{-\frac{\|y_{\omega^\perp}\|^2}2} \int\mclimits_{\langle x, \omega\rangle = 0}e^{-\frac{\|y_{\omega^\perp}\|^2}2 + \langle x, y_{\omega^\perp}\rangle - \frac{\|x\|^2}2} (2\pi)^{-\frac{n-1}2} ~dx
    \\&= e^{-\frac{\|y_{\omega^\perp}\|^2}2} \int\mclimits_{\langle x, \omega\rangle = 0}e^{-\frac{\|x - y_{\omega^\perp}\|}2} (2\pi)^{-\frac{n-1}2} ~dx
    % \\&= e^{-\frac{\|p_{\omega^\perp}\|^2}2}
  \end{align*}
  which is just $e^{-\frac{\|p_{\omega^\perp}\|^2}2}$. It was important here to invoke the orthogonal projection $y_{\omega^\perp}$ so that the integrand becomes the translation of a standard Gaussian function on the hyperplane $\langle x, \omega \rangle = 0$. Now returning to (\ref{eq:GRTPhiExpansion21}), we have
  \begin{align*}
    GR_{\phi}(\omega, p) 
      &= e^{p \langle \omega, y\rangle - \frac{\|y\|^2}2-\frac{\|y_{\omega^\perp}\|^2}2}
    \\
      &= e^{p \langle \omega, y\rangle - \frac{\langle y, \omega\rangle^2}2}
  \end{align*}
  where we used (\ref{eq:GRTPhiExpansion22}). This looks like the generating function for the univariate Hermite polynomials $H_k(p)$ with $t = \langle \omega, y \rangle$, so we expand
  \begin{align*}
    GR_{\phi}(\omega, p) 
      &= \sum_{k = 0}^\infty \frac{H_k(p)}{k!} \langle \omega, y\rangle^k.
  \end{align*}
  Finally we apply the multinomial expansion of $\langle \omega, y\rangle^k$, recalling the multinomial coefficients $\binom{k}{\alpha} = \frac{k!}{\alpha!}$. Therefore
  \begin{align*}
    GR_{\phi}(\omega, p)
      &= \sum_{k = 0}^\infty \sum_{|\alpha| = k} \frac{H_k(p)}{k!} \binom{k}\alpha y^\alpha\omega^\alpha
    \\
      &= \sum_{k = 0}^\infty \sum_{|\alpha| = k} \frac{H_k(p)\omega^\alpha}{\alpha!} y^\alpha
  \end{align*}
  as needed.
\end{proof}

\begin{remark}
  The proof above was written by Dr. Sengupta. Recall that the Hermite polynomials $H_\alpha$ form a complete orthogonal basis for $L^2(\RR^n, w_n)$. In this sense the formula (\ref{eq:GRH}) completely defines the Gaussian Radon transform on this space. Indeed, it can be shown that any function $f \in L^2(\RR^n, w_n)$ has an expansion
  \[
    f(x) = \sum_{\alpha \in \NN_0^n} a^{(f)}_\alpha H_\alpha(x)
  \]
  where
  \[
    a_\alpha^{(f)} = \int_{\RR^n} f(x)H_\alpha(x) w_n(x) ~dx.
  \]
  If this expansion converges nicely on $\Lambda$ then
  \begin{align*}
    GR_f(\Lambda) 
    &= \int_\Lambda f(x) w_n(x-p_0)~dx 
    \\ 
    &= \int_\Lambda \sum_{\alpha \in \NN_0^n} a_\alpha^{(f)} H_\alpha(x) w_n(x-p_0) ~dx
    \\
    &= \sum_{\alpha \in \NN_0^n} a_\alpha^{(f)} \int_\Lambda H_\alpha(x) w_n(x-p_0) ~dx
    \\
    &= \sum_{\alpha \in \NN_0^n} a_\alpha^{(f)} GR_{H_\alpha}(\Lambda)
  \end{align*}
  If $\Lambda$ is a hyperplane $\inner{x, \omega} = p$ with $\omega \in S^{n-1}$ then this gives
  \begin{align*}
    GR_f(\Lambda) 
    &= \sum_{\alpha \in \NN_0^n} a_\alpha^{(f)} GR_{H_\alpha}(\Lambda)
    \\
    &= \sum_{\alpha \in \NN_0^n} a_\alpha^{(f)} H_{|\alpha|}(p) \omega^\alpha
    \\
    &= \sum_{k=0}^\infty H_k(p) \sum_{|\alpha| = k} a_\alpha^{(f)} \omega^\alpha
  \end{align*}
  For details on modes convergence see (Dunkl or Thangavelu) \cn. 
\end{remark}

\section{The GRT of multivariate polynomials over general affine subspaces}

% The goal of this section will be to explore the generalizations of the RT and GRT as functions of general affine subspaces. We discuss the analogues of many of the previous results in this context.

In section 1.4 we defined the RT and GRT as the integrals of a function $f: \RR^n \rightarrow \RR$ over $n-1$ dimensional hyperplanes, the standard definitions. But there are many examples of geometric integral transforms, closely related to the hyperplane RT, which can be thought of as ``generalized Radon transforms''. In fact, the ``Funk transform'', which relates a function on the sphere $S^{3}$ to its integrals over great circles, was first introduced by Paul Funk in 1911, half a decade before Radon introduced the hyperplane RT.\. In the remainder of this chapter we discuss the notion of the RT and GRT on general $d$-dimensional affine subspaces of $\RR^n$, where $d = 0, \ldots, n$. For context, note that when $d = 1$, this is the so called ``X-ray transform'' which gets it's name from the direct application to radiology.

Let $\Lambda_0$ be a $d$-dimensional linear subspace of $\RR^n$, and $v \in \RR^n$. Then the translation of $\Lambda_0$ by $v$
\[
  \Lambda = v + \Lambda_0
\]
is called an \emph{affine subspace} of $\RR^n$. The representation above is clearly not unique since adding any member of $\Lambda_0$ to $v$ does not change $\Lambda$. However, given an affine subspace $\Lambda$ we have a canonical choice for $v$ as the closest point in $\Lambda$ to the origin. This point exists and is unique since $\Lambda$ is closed and convex. Furthermore the point $v$ defined in this way must be orthogonal to any vector in the linear subspace $\Lambda_0$. That is, $v \in \Lambda_0^\perp$, where $\Lambda_0^\perp$ is the linear subspace
\[
  \Lambda_0^\perp = \{x \in \RR^n : \langle x, y \rangle = 0 \text{ for all } y \in \Lambda\}
\]
also known as the \emph{orthogonal complement} of $\Lambda_0$. Thus we rephrase our definition as follows:

\begin{definition}
  An \emph{affine subspace} $\Lambda$ of dimension $d$ in $\RR^n$ is defined uniquely by
  \[
    \Lambda = v + \Lambda_0
  \]
  where $\Lambda_0$ is a linear subspace of dimension $d$ and $v \in \Lambda_0^\perp$. Sometimes we call $\Lambda$ a ``$d$-plane''.
\end{definition}

\begin{remark}
  Note that the hyperplanes in the original definition of the RT are $(n-1)$-planes, and the lines in the ``X-ray transform'' are $1$-planes.
\end{remark}

Recall that if $\Lambda_0$ is a fixed linear subspace of dimension $d$, the orthogonal complements $\Lambda_0^\perp$ is a linear subspace of dimension $n - d$. For any $x \in \RR^n$ there is a unique orthogonal decomposition $x = x_{\Lambda_0} + x_{\Lambda_0^\perp}$ where $x_{\Lambda_0} \in \Lambda_0$ and $x_{\Lambda_0^\perp} \in \Lambda_0^\perp$. This idea can be summarized by the expression
\[
  \RR^n = \Lambda_0 \oplus \Lambda_0^\perp.
\]

Sometimes it is convenient to have an explicit coordinate system on an affine subspace. If $u^{(1)}, \ldots, u^{(d)}$ is a orthonormal basis for $\Lambda_0$ then there is an isometric embedding of $\RR^d$ into $\RR^n$ with image $\Lambda$ given by $x(t) : \RR^d \rightarrow \Lambda$ where
\[
  x(t) = v + t_1u^{(1)} + \cdots + t_d u^{(d)}, \qquad t \in \RR^d.
\]
By this embedding can define the Euclidean measure $dx$ on $\Lambda$ as the push-forward of the Lebesgue measure on $\RR^n$, and the standard Gaussian measure on $\Lambda$ as the push-forward of $\gamma^n$. Note the $x(t)$ is defined in such a way that $x(0) = v$ which is essential when defining the Gaussian measure on $\Lambda$.

Other times we prefer not to invoke a basis-dependent isometry, and while $x(t)$ clearly depends on the choice of $u^{1}, \ldots, u^{(d)}$, we should note that the Euclidean and Gaussian measures on $\Lambda$ are independent of basis \cn.


Now we can define the natural analogue of the RT for affine subspaces, which is sometimes called the \emph{$d$-plane transform}. To be consistent with the hyperplane RT we will write $v = p\omega$, where $\omega \in S^{n-1} \cap \Lambda_o^\perp$ and $p \in \RR$. Of course this notation is unique only up to the identification $(\omega, p) = (-\omega, -p)$.

\begin{definition}
  Let $f:\RR^n \rightarrow \RR$. For any affine subspace $\Lambda = p\omega + \Lambda_0$, we define the \emph{Radon Transform of $f$ on $\Lambda$} by
  \[
    R_f(\Lambda) = \int_{\Lambda} f(x)~dx
  \]
  and the \emph{Gaussian Radon Transform of $f$ on $\Lambda$} by 
  \[
    GR_f(\Lambda) = \int_{\Lambda} f(x) w_d(x - p\omega) ~dx
  \]
  where $d$ is the dimension of the linear subspace $\Lambda_0$.
\end{definition}
\begin{remark}
  Explicitly, if $x(t): \RR^d \rightarrow \Lambda$ is an Euclidean isometry then 
  \[
    R_f(\Lambda) = \int_{\RR^d} f(x(t))~dt
  \]
  If furthermore $x(0) = p\omega$ then
  \[
    GR_f(\Lambda) = \int_{\RR^d} f(x(t))w(t)~dt
  \]
  However keep in mind that these definitions are independent of the particular isometry \pn.
\end{remark}

In order to generalize the formula (\ref{eq:GRH}) we begin with the integral of $H_\alpha$ over linear subspaces.

Recall that the GRT of a function $f$ over a linear subspace $\Lambda_0$ can be written
\begin{equation} \label{eq:GRRot}
  GR_f(\Lambda_0) = \int\mclimits_{\RR^d \times {\{0\}}^{n-d}} f(Rx) w_d(x) ~dx
\end{equation}
where $R \in SO(n)$ is the a rotation sending $\RR^d \subseteq \RR^n$ to $\Lambda_0$. Thus we would like to investigate the action of rotations on certain functions of interest, namely monomials and Hermite polynomials.

\begin{lemma}
  Let $f(x) = x^\alpha$ for some multi-index $\alpha \in \NN_0^n$ of degree $|\alpha| = k$. Then the rotation $f(Rx)$ has the expansion
  \begin{equation} \label{eq:monRot}
    f(Rx) = \sum_{\substack{\beta \in \NN_0^n \\ |\beta| = k}} c(R)^\alpha_\beta x^{\beta}.
  \end{equation}
  The coefficients $c(R)^\alpha_\beta$ are given by
  \[
    c(R)^\alpha_\beta 
    % = \binom{k}{\beta} \inner{P_s\bf{e}^{\otimes \beta}, \bf{e}^{\otimes \alpha}} = \sum_{i \in I(\beta)} \inner{\bf{e}_{\otimes i}, \bf{e}^{\otimes \alpha}}
    % = \sum_{i \in I(\beta)} \prod_{j = 1}^n \inner{Re_{i_j}, e_{\alpha^j}}
    = \sum_{i \in I(\beta)} \prod_{j = 1}^n \inner{Re_{i_j}, e_{\alpha^j}}
  \]
  where $\alpha^j = \ell$ if $0 < j - \alpha_1 - \cdots \alpha_{\ell - 1} \leq \alpha_\ell$ and
  \[
    I(\beta) = \{i \in \{1, \ldots, n\}^k: \hbox{$1, \ldots, n$ have multiplicity $\beta_1, \ldots \beta_n$ in $i$}\}
  \]
  Note that the inner products $\inner{Re_{i_j}, e_{\alpha^j}}$ are matrix entries for $R$. 
\end{lemma}
\begin{proof}
  First one should note that $(Rx)^\alpha$ is a homogeneous polynomial of degree $k$; a polynomial because $R$ is a linear transformation, and homogeneous because $R \in SO(n)$ so that for $\lambda \in \RR$,
  \[
    (R\lambda x)^\alpha = (\lambda Rx)^\alpha = \lambda^k (Rx^\alpha).
  \]
  Using the tensor power notation from appendix A, we can write
  \[
    (Rx)^\alpha = \prod_{i = 1}^n \inner{Rx, e_i}^{\alpha_i} = \inner{R^{\otimes k} x^{\otimes k}, \bf{e}^{\otimes \alpha}} = \inner{x^{\otimes k}, {(R^{-1})}^{\otimes k}\bf{e}^{\otimes \alpha}}
  \]
  Now we expand over the basis ${\{\bf{e}_{\otimes i}\}}_{i \in {\{1, \ldots, n\}}^k}$, noting that each tuple $i \in {\{1, \ldots, n\}}^k$ is an anagram to exactly one multiindex of degree $k$. To be precise ${\{I(\beta)\}}_{|\beta| = k}$ is a partition of ${\{1, \ldots, n\}}^k$.
  Thus 
  \begin{align*}
    \inner{x^{\otimes k}, {(R^{-1})}^{\otimes k}\bf{e}^{\otimes \alpha}}
      % &= \sum_{\substack{\beta \in \NN_0^n \\ |\beta| = k}} \sum_{i \in I(\beta)} \inner{x^{\otimes k}, (R^{-1})^{\otimes k}\bf{e}^{\otimes \alpha}} \\
      &= \sum_{\substack{\beta \in \NN_0^n \\ |\beta| = k}} \sum_{i \in I(\beta)} \inner{x^{\otimes k}, \bf{e}_{\otimes i}} \inner{\bf{e}_{\otimes i}, {(R^{-1})}^{\otimes k}\bf{e}^{\otimes \alpha}} \\
      &= \sum_{\substack{\beta \in \NN_0^n \\ |\beta| = k}} x^\beta \sum_{i \in I(\beta)} \inner{\bf{e}_{\otimes i}, {(R^{-1})}^{\otimes k}\bf{e}^{\otimes \alpha}}.
  \end{align*}
  That we have the non-tensor expression 
  \[
    \inner{\bf{e}_{\otimes i}, {(R^{-1})}^{\otimes k}\bf{e}^{\otimes \alpha}} = \prod_{j = 1}^n \inner{e_{i_j}, R^{-1}e_{\alpha^j}} = \prod_{j = 1}^n \inner{Re_{i_j}, e_{\alpha^j}}
  \]
  follows from the definition of the inner product on ${(\RR^n)}^{\otimes k}$ and further notation from appendix A.
\end{proof}
\begin{remark}
  We could write the coefficient $c(R)^\alpha_\beta$ in a slightly different form. If we define the non-decreasing tuple $\tilde{\alpha}$ associated with a multi-index $\alpha$ by
  \[
    \tilde{\alpha} = (\underbrace{1, \ldots, 1}_{\alpha_1 ~\text{times}}, \underbrace{2, \ldots, 2}_{\alpha_2 ~\text{times}}, \ldots , \underbrace{n, \ldots, n}_{\alpha_n ~\text{times}})
  \]
  then 
  \[
    c(R)^\alpha_\beta = \sum_{\sigma \in S_k} \prod_{j = 1}^n R_{\sigma \tilde{\beta}_j, \tilde{\alpha}_j}. 
  \]
  % is similar in form to the matrix determinant.
\end{remark}
\begin{myexample}
  For a simple example take the monomial $f(x) = x_1^2x_2$. Here $n = 2$, $\alpha = (2, 1)$ and $k = 3$. The partition of ${\{1, 2\}}^3$ over multi-indices $|(\beta_1, \beta_2)| = 3$ is given by
  \begin{align*}
    I(3,0) &= \{(1, 1, 1)\} \\
    I(2,1) &= \{(1, 1, 2), (1, 2, 1), (2, 1, 1)\} \\
    I(1,2) &= \{(1, 2, 2), (2, 1, 2), (2, 2, 1)\} \\
    I(0,3) &= \{(2, 2, 2)\}
  \end{align*}
  Now note that $(\alpha^1, \alpha^2, \alpha^3) = (1, 1, 2)$. If $R \in SO(2)$ is a $2 \times 2$ rotation matrix with entries $R_{i,j} = \inner{Re_i, e_j}$ then the formula (\ref{eq:monRot}) says 
  \begin{align*}
    (Rx)^\alpha 
    &= x_1^3 R_{1,1}^2 R_{1,2} \\
    &+ x_1^2x_2 \left(R_{1,1}^2R_{2,2} + 2R_{1,1}R_{2,1}R_{1,2}\right) \\
    &+ x_1x_2^2 \left(2R_{1,1}R_{2,1}R_{2,2} + R_{2,1}^2R_{1,2}\right) \\
    &+ x_2^3 R_{2,1}^2 R_{2,2}
  \end{align*}
  While tensor power notation is concise, this sort of representation is needed for computation.
\end{myexample}

\begin{proposition}
  The GRT of a monomial $f(x) = x^\alpha$ on a linear subspace $\Lambda_0$ is given by
  \[
    GR_f(\Lambda_0) = \sum_{\substack{\beta \in \NN_0^n \\ |\beta| = k}} c(R)^\alpha_\beta c^G_{\beta}
  \]
  where $c^G_\beta = \int_{\RR^d} x^\beta w_d(x) ~dx$ are the Gaussian moments on $\RR^d$. \emph{This should be indexed by only the first $d$ entries of $\beta$. Feels weird}.
\end{proposition}

\begin{proof}
  We take (\ref{eq:GRRot}),
  \[
    GR_f(\Lambda_0) = \int\mclimits_{\RR^d \times {\{0\}}^{n-d}} {(Rx)}^\alpha w_d(x) ~dx,
  \]
  and expand by (\ref{eq:monRot}),
  \begin{align*}
    \int\mclimits_{\RR^d \times {\{0\}}^{n-d}} (Rx)^\alpha w_d(x) ~dx
    &= \sum_{\substack{\beta \in \NN_0^n \\ |\beta| = k}} {c(R)}^\alpha_\beta \int_{\RR^d \times {\{0\}}^{n-d}} x^\beta w_d(x) ~dx
  \end{align*}
  as needed.
\end{proof}

\begin{proposition}
  The GRT of a multivariate Hermite polynomial $H_\alpha$ on an affine subspace $\Lambda$ is given by
  \[
    GR_{H_\alpha}(\Lambda) = \alpha! \sum_{\substack{\beta \in \NN_0^n \\ |\beta| = |\alpha|}} {c(P_{\Lambda_0^\perp})}^\beta_\alpha \frac{H_\beta(p_0)}{\beta!}
  \]
\end{proposition}

\begin{proof}
  Once again we take the GRT of the generating function $\phi(x) = e^{\inner{x, y} - \frac{\norm{y}^2}2}$, initially expanding
  \[
    GR_{\phi}(\Lambda) = \sum_{\alpha \in \NN_0^n} \frac{GR_{H_\alpha}(\Lambda)}{\alpha!} y^\alpha
  \]
  Simultaneously we have
  \begin{align*}
    GR_\phi(\Lambda) 
    &= e^{\inner{p_0, y} -\frac{\norm{y}^2}2} (2\pi)^{-\frac{d}2}\int_{\Lambda} e^{\inner{x, y} - \frac{\norm{x}^2}2}~dx \\
    &= e^{\inner{p_0, y} - \frac{\norm{y}^2}2 + \frac{\norm{P_{\Lambda_0} y}^2}2} \\
    &= e^{\inner{p_0, y} - \frac{\norm{P_{\Lambda_0^\perp} y}^2}2} \\
    &= \sum_{\alpha \in \NN_0^n} \frac{H_\alpha(p_0)}{\alpha!} {(P_{\Lambda_0^\perp} y)}^\alpha
  \end{align*}
  Now we should have noted that the formula (\ref{eq:monRot}) applies not only to rotations but to any linear transformation, so we have 
  \begin{align*}
    GR_\phi(\Lambda) 
    &= \sum_{\alpha \in \NN_0^n} \frac{H_\alpha(p_0)}{\alpha!} \sum_{\substack{\beta \in \NN_0^n \\ |\beta| = |\alpha|}} {c(P_{\Lambda_0^\perp})}^\alpha_\beta y^\beta \\
    &= \sum_{\beta \in \NN_0^n} y^\beta \sum_{\substack{\alpha \in \NN_0^n \\ |\alpha| = |\beta|}} {c(P_{\Lambda_0^\perp})}^\alpha_\beta  \frac{H_\alpha(p_0)}{\alpha!}
  \end{align*}
  Comparing coefficients we conclude.
  \[
    \frac{GR_{H_\alpha}(\Lambda)}{\alpha!} = \sum_{\substack{\beta \in \NN_0^n \\ |\beta| = |\alpha|}} {c(P_{\Lambda_0^\perp})}^\beta_\alpha \frac{H_\beta(p_0)}{\beta!}
  \]
\end{proof}

% \begin{myexample}
%   Let $n = 3, k = 1$
% \end{myexample}


% We may note that the linear subspace $\Lambda_0$ is a rotation of $\RR^d \subseteq \RR^n$, that is there exists some $R \in SO(n)$ so that $\Lambda_0 = R(\RR^d)$. In particular
% \[
%   GR_f(\Lambda_0) = \int_{\RR^d} f(Rx)w(x)~dx.
% \]
% Since $R$ is a linear transformation $H_\alpha(Rx)$ is a polynomial of degree $|\alpha|$, it can be written in terms of the basis $H_\beta$ with $|\beta| = k$
% \[
%   H_\alpha(R(x)) = \sum_{|\beta| = k} C(R)^\alpha_\beta H_\beta(x).
% \]
% In determining the coefficients $C^\alpha_\beta(R)$ we will use the tensor product notation described in detail in appendix A. For clarity, we will write
% \[
%   x^{\otimes k} = \underbrace{x \otimes x \otimes \cdots \otimes x}_{\hbox{$k$ times}}
% \]
% and with the vector notation ${\bf e} = (e_1, \ldots, e_n) \in (\RR^n)^n$,
% \begin{align*}
%   {\bf e}_{\otimes i} &= e_{i_1} \otimes e_{i_2} \otimes \cdots \otimes e_{i_k} 
%   \\
%   {\bf e}^{\otimes \alpha}
%   &= e_1^{\otimes \alpha_1} \otimes \cdots \otimes e_n^{\otimes \alpha_n}
%   \\
%   &= \underbrace{e_1 \otimes \cdots \otimes e_n}_{\hbox{$\alpha_1$ times}} \otimes \cdots \otimes \underbrace{e_n \otimes \cdots \otimes e_n}_{\hbox{$\alpha_n$ times}}
% \end{align*}
% where $i = (i_1, \ldots i_n) \in \{1, \ldots n\}^k$ and $\alpha \in \NN_0^n$. An inner product on tensors is defined by
% \[
%   \inner{x_1 \otimes x_2 \otimes \cdots \otimes x_k,~ y_1 \otimes y_2 \otimes \cdots \otimes y_k}
%   = \inner{x_1, y_1} \inner{x_2, y_2} \cdots \inner{x_k, y_k}.
% \]  
% Thus we can express the monomial $x^\alpha$ with degree $|\alpha| = k$ as
% \[
%   x^\alpha 
%   = \prod_{i = 1}^n \inner{x, e_i}^{\alpha} 
%   = \inner{x^{\otimes k}, {\bf e}^{\otimes \alpha}}
% \]
% Since this expression is clearly independent of the particular order of the elements of ${\bf e}^{\otimes \alpha}$ we call the collection of its distinct anagrams of $I(\alpha)$. 
% % introduce the symmetrization operator
% % \[
% %   P_s(v_1 \otimes v_2 \otimes \cdots v_k) = \frac1{k!}\sum_{\sigma \in S_k} v_{\sigma^{-1}1} \otimes v_{\sigma^{-1}2} \otimes \cdots \otimes v_{\sigma^{-1}k}
% % \]
% \begin{lemma}
%   The action of a rotation $R \in SO(n)$ on the monomial $x^\alpha$ of degree $|\alpha| = k$ has the expansion
%   \[
%     (Rx)^\alpha = \sum_{|\beta| = k} x^{\alpha} \binom{k}{\beta} \sum_{i \in I(\alpha)} \inner{e_{\otimes i}, (R^{-1})^{\otimes k}{\bf e}^{\otimes \alpha}}
%   \]
% \end{lemma}
% Now consider the action of a rotation $R \in SO(n)$ on the monomial. First it should be noted that $(Rx)^\alpha$ is a polynomial, since $R$ is a linear transformation. Furthermore for any scalar $\lambda$ we have
% \[
%   (R(\lambda x))^\alpha = (\lambda Rx)^\alpha = \lambda^k (Rx)^\alpha
% \]
% so that it is remains homogeneous polynomial of degree $k$. Now introducing the tensor notation above we have
% \begin{align*}
%   (Rx)^\alpha 
%   &= \inner{(Rx)^{\otimes k}, {\bf e}^{\otimes \alpha}}
%   \\
%   &= \inner{R^{\otimes k} x^{\otimes k}, {\bf e}^{\otimes \alpha}}
%   \\
%   &= \inner{x^{\otimes k}, (R^{-1})^{\otimes k}{\bf e}^{\otimes \alpha}}
%   \\
%   &= \inner{x^{\otimes k}, (R^{-1}{\bf e})^{\otimes \alpha}}
% \end{align*}
% where we use the shorthand $R^{-1}{\bf e} = (R^{-1}e_1, \ldots, R^{-1}e_n)$. Now recall that $\{e_{i_1} \otimes e_{i_2} \otimes \cdots \otimes e_{i_k} : (i_1, \ldots, i_k) \in I^k\}$ where $I = \{1, \ldots n\}$ is a basis for the vector space $(\RR^n)^{\otimes k}$ of $k$-tensors, so that
% \[
%   \inner{x^{\otimes k}, (R^{-1}{\bf e})^{\otimes \alpha}} 
%   = \sum_{(i_1, \ldots, i_k) \in I^k} \inner{x^{\otimes k}, e_{i_1} \otimes \cdots \otimes e_{i_k}}\inner{e_{i_1} \otimes \cdots \otimes e_{i_k}, (R^{-1}{\bf e})^{\otimes \alpha}}
% \]


% Let's take a moment to investigate the coefficients in this expansion. Take for an example $n = 3$, $k = 6$, $\alpha = (2, 1, 3)$, $\beta = (2, 2, 2)$. The tensors ${\bf e}^\beta$ and $(R^{-1}{\bf e})^{\alpha}$ are 
% \begin{align*}
%   {\bf e}^\beta &= &e_1 &\otimes &e_1 &\otimes &e_2 &\otimes &e_2 &\otimes &e_3 &\otimes &e_3
%   \\
%   (R^{-1}{\bf e})^{\alpha} &= &R^{-1}e_1 &\otimes &R^{-1}e_1 &\otimes &R^{-1}e_2 &\otimes &R^{-1}e_3 &\otimes &R^{-1}e_3 &\otimes &R^{-1}e_3
% \end{align*}
% which gives the itemwise inner product
% \begin{align*}
%   \inner{{\bf e}^{\otimes \beta}, (R^{-1}{\bf e})^{\otimes \alpha}} 
%     &= &\inner{e_1, R^{-1}e_1} \inner{e_1, R^{-1}e_1} \inner{e_2, R^{-1}e_2} 
%     \\
%     &~ &\inner{e_2, R^{-1}e_3} \inner{e_3, R^{-1}e_3} \inner{e_3, R^{-1}e_3}
% \end{align*}

% Then with $f(x) = x^\alpha$
% \begin{align*}
%   GR_f(\Lambda_0) 
%   &= \int_{\RR^d}(Rx)^\alpha w_d(x) ~dx
%   \\
%   &= \int_{\RR^d} \sum_{|\beta| = k} \inner{{\bf e}^{\otimes \beta}, (R^{-1}{\bf e})^{\otimes \alpha}} x^\beta w_d(x) ~dx
%   \\
%   &= \sum_{|\beta| = k} \inner{{\bf e}^{\otimes \beta}, (R^{-1}{\bf e})^{\otimes \alpha}} \int_{\RR^d}x^\beta w_d(x) ~dx
%   \\
%   &= \sum_{|\beta| = k} \inner{{\bf e}^{\otimes \beta}, (R^{-1}{\bf e})^{\otimes \alpha}} c^G_\beta
% \end{align*}
% where $c^G_\beta$ are the Gaussian moments on $\RR^d$
% \[
%   c^G_\beta 
%   = \int_{\RR^d} x^\beta w_d(x) ~dx 
%   = 
%   \begin{cases}
%     \prod_{i = 1}^n (\beta_\ell - 1)!! & \hbox{every $\beta_i$ even} \\
%     0 & \hbox{any $\beta_i$ odd}
%   \end{cases}
% \]

% Once again taking the generating function $\phi(x) = e^{\inner{x,y} - \frac{\norm{y}^2}2}$, we have
% \[
%   GR_\phi(\Lambda_0) 
%   = \int_{\RR^d} e^{\inner{Rx,y} - \frac{\norm{y}^2}2}
%   = \int_{\RR^d} e^{\inner{x,R^{-1}y} - \frac{\norm{R^{-1}y}^2}2}
%   = \sum_{\alpha \in \NN_0^n} \frac{H}
% \]

% In order to generalize the formula (\ref{eq:GRH}) to the general extended GRT setting it is useful to begin with a discussion of rotations of monomials. Suppose $R \in O(n)$, that is $R : \RR^n \to \RR^n$ is a linear isomorphism satisfying
% \[
%   R^\top R = RR^\top = I
% \]
% Since a linear subspace $\Lambda_0$ of dimension $d = 0, \ldots, n$ can be written as $R(\RR^d)$ for some $R \in O(n)$, and thus the affine subspace $\Lambda = p\omega + \Lambda_0$ as
% \[
%   \Lambda = p\omega + R(\Lambda_0),
% \]
% we can redefine the RT and GRT correspondingly. In particular,
% \[
%   GR_f(\Lambda) = \int_{\RR^d} f(p\omega + R^{-1}x)w(x)~dx
% \]
% For monomials $f(x) = x^\alpha$, $\alpha \in \NN_0^n$, we have
% \begin{align*}
%   f(R^{-1}x) 
%     &= (R^{-1}x)^\alpha
%     \\ 
%     &= (\sum_{i = 1}^n \inner{R^{-1}x, e_i})e_i)^\alpha
%     \\
%     &= \prod_{i = 1}^n \inner{R^{-1}x, e_i}^{\alpha_i}
%     \\
%     &= \prod_{i = 1}^n \inner{x, Re_i}^{\alpha_i}
% \end{align*}




% To illustrate the calculation of a GRT with an explicit isometry, let
% \[
%   f(x) = e^{\langle x, y\rangle}
% \]
% for some $y \in \RR$. Suppose $\Lambda = p\omega + \Lambda_0$ is a $d$-dimensional affine subspace, where $\Lambda$ is a linear subspace, $\omega \in \Lambda_0^\perp$, $y \in \RR$, and let $x(t) : \RR^d \rightarrow \Lambda$ be the isometry given by
% \[
%   x(t) = p\omega + \sum_{i = 1}^d t_iu^{(i)}
% \]
% where $u^{(1)}, \ldots, u^{(d)}$ is an orthonormal basis for $\Lambda_0$. Furthermore let $y = y_{\Lambda_0} + y_{\Lambda_0^\perp}$ and note that $\langle x, y \rangle = \langle x, y_{\Lambda_0}\rangle$ for $x \in \Lambda_0$. Then
% \begin{align*}
%   GR_f(\Lambda) 
%     &= \int_{\RR^d} e^{\langle x(t), y \rangle} (2\pi)^{-\frac{d}2} e^{-\frac{\|t\|^2}2}~dt
%   \\
%     &= e^{p \langle \omega, y \rangle} \int_{\RR^d} e^{\sum_{i = 1}^d t_i\langle u^{(i)}, y_{\Lambda_0}\rangle - \frac{\|t\|^2}2} (2\pi)^{-\frac{d}2} ~dt
%   \\
%     &= e^{p \langle \omega, y \rangle} \int_{-\infty}^\infty \prod_{i=1}^d e^{t_i\langle u^{(i)}, y_{\Lambda_0}\rangle - \frac{t_i^2}2} (2\pi)^{-\frac12} dt_i
% \end{align*}
% Now notice in each exponential in the product we can complete the square $\|t_iu^{(i)} - y_{\Lambda_0}\|^2 = \|y_{\Lambda_0}\|^2 - 2t_i\langle u^{(i)}, y_{\Lambda_0}\rangle + t_i^2$, that is
% \[
%   e^{t_i\langle u^{(i)}, y_{\Lambda_0}\rangle - \frac{t_i^2}2}
%     = e^{\frac12\|y_{\Lambda_0^\perp}\|}e^{-\frac12\|t_iu^{(i)} - y_{\Lambda_0}\|^2}
% \]
% for $i = 1, \ldots, d$. The right hand integral is a Gaussian integral equal to $1$. Thus
% \[
%   GR_f(\Lambda) = e^{p \langle \omega, y \rangle} \prod_{i=1}^d 
% \]

% Let's see if we can derive a formula for the GRT of the multivariate Hermite polynomials on a general affine plane.

% Following the proof for the hyperplane GRT, we begin again with the transform of the generating function $\phi(x)$,
% \[
%   GR_\phi(\Lambda)
%     = \int_{\Lambda_0} \phi(x) w_d(x - p\omega) ~dx
% \]
% which can be immediately expanded as 
% \[
%   GR_\phi(\Lambda) = \sum_{\alpha!}\frac{GR_{H_\alpha}(\Lambda)}{\alpha!}y^\alpha.
% \]
% At the same time we can translate the integral over to $\Lambda_0$ such that
% \[
%   GR_\phi(\Lambda)
%     = e^{p\langle \omega, y\rangle - \frac{\|y\|^2}2} \int_{\Lambda_0} e^{\langle x, y\rangle - \frac{\|x\|^2}2} (2\pi)^{-\frac d2}~dx
% \]
% As before, we decompose $y = y_{\Lambda_0} + y_{\Lambda_0^\perp}$, substitute $y_{\Lambda_0}$ for $y$ and complete the square so that the right hand integral is $e^{\frac{\|y_{\Lambda_0}\|^2}2}$.
% \[
%   GR_\phi(\Lambda) 
%     = e^{p\langle \omega, y\rangle - \frac{\|y\|^2}2 + \frac{\|P_{\Lambda_0} y\|}2}
% \]
% Now we have $\|y\|^2 = \|y_{\Lambda_0}\|^2 + \|y_{\Lambda_0^\perp}\|^2$, so
% \[
%   GR_\phi(\Lambda) 
%     = e^{p\langle \omega, y\rangle - \frac{\|y_{\Lambda_0^\perp}\|^2}2}
% \]
% Here we encounter a problem we didn't see in the hyperplane case: 
% In the hyperplane case $\dim(\Lambda_0^\perp) = 1$ so that $y_{\Lambda_0^\perp}$ was necessarily in the span of $\omega$. But for lower dimensional affine subspaces there is no immediate relation between $y_{\Lambda_0^\perp}$ and $\langle \omega, y\rangle$. 

% If we suppose for the moment that $y \in \Lambda_0^\perp$. Then we do have 
% \[
%   GR_\phi(\Lambda) 
%     = e^{p\langle \omega, y\rangle - \frac{\|y\|^2}2}
%     = \sum_{\alpha \in \NN_0^n} \frac{H_{\alpha}(p\omega)}{\alpha!}y^\alpha
% \]
% so can we conclude $GR_{H_\alpha}(\Lambda) = H_\alpha(p\omega)$? That doesn't feel right.

% If we further suppose that $y$ is in the span of $\omega$ then we find
% \[
%   something else
% \]
% via Ambar.

% What if we just assume $\|y_{\Lambda_0^\perp}\|^2 = \langle\omega, y\rangle^2$? This is true essentially if $y \in \omega\RR + \Lambda_0$. In this case we have what we want,
% \[
%   \sum_{\alpha \in \NN_0^n} \frac{GR_{H_\alpha}(\Lambda)}{\alpha!} y^\alpha = \sum_{k=0}^\infty \sum_{|\alpha| = k} \frac{H_k(p)\omega^\alpha}{\alpha!} y^\alpha
% \]
% It doesn't seem like it should be enough for this to hold on a $d+1$ subspace, to conclude that we can compare coefficients. 

% Now if $\omega$ and $P_{\Lambda_0^\perp} y$ are potentially linearly independent, where can we go from here?

% Recall $\omega$ was chosen from $S^{n-1} \cap \Lambda_0^\perp$ and $y \in \RR^n$ is arbitrary, while $P_{\Lambda_0^\perp} y$ is in $\Lambda_0^\perp$. Suppose that $v^{(1)}, \ldots, v^{(n - d)}$ is an orthonormal basis for $\Lambda_0^\perp$. We can write
% \[
%   \omega = \sum_{i = 1}^{n-d} r_i v^{(i)}, \qquad y = \sum_{i = 1}^{n-d} s_i v^{(i)}
% \]
% for some $r,s \in \RR^{n-d}$.

% Is it true that $\langle \omega, y \rangle = \langle \omega, P_{\lambda_0^\perp} y\rangle$? Well, yes: $y = P_{\Lambda_0} y + P_{\Lambda_0^\perp} y$, so
% \[
%   \langle \omega, y \rangle = \langle \omega, P_{\Lambda_0} y \rangle + \langle \omega, P_{\Lambda_0^\perp} y \rangle
% \]
% and $\langle \omega, P_{\Lambda_0} y \rangle = 0$. Then 
% \begin{align*}
%   e^{p\langle \omega, y\rangle - \frac{\|P_{\Lambda_0^\perp} y\|^2}2}
%     &= e^{p\langle \omega, P_{\Lambda_0^\perp} y \rangle - \frac{\|P_{\Lambda_0^\perp} y\|^2}2}
%   \\&= \sum_{\alpha \in \NN_0^n} \frac{H_\alpha(p\omega)}{\alpha!} (P_{\Lambda_0^\perp} y)^\alpha
%   \\&=? \sum_{\alpha \in \NN_0^{n-d}} \frac{H_\alpha(p\omega)}{\alpha!} (P_{\Lambda_0^\perp} y)^\alpha
% \end{align*}
% We still cannot compare coefficients with
% \[
%   \int_\Lambda e^{\langle x, y\rangle - \frac{\|y\|^2}2} w_{d}(x -p\omega)~dx
%     = \sum_{\alpha \in \NN_0^n} \frac{GR_{H_\alpha}(\omega, p)}{\alpha!} y^\alpha
% \]